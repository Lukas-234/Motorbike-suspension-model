import numpy as np
from scipy.linalg import eigh
import matplotlib.pyplot as plt
import pandas as pd
from scipy import interpolate
from scipy.integrate import solve_ivp
from scipy.signal import butter, filtfilt

def k_finder(f_target, m_s, m_u, m_d, k_t):
    m_total=m_u+m_s
    k_estimate = (2 * np.pi * f_target)**2 * m_total
    k_s_lower = 0.5 * k_estimate
    k_s_higher = 2 * k_estimate
    def rf_func(k_s):
        """
        Returns: actual_frequency - target_frequency
        Root when this equals zero
        """
        K = np.array([[k_s, -k_s], 
                      [-k_s, k_s + k_t]])
        M = np.array([[m_s + m_d, 0], 
                      [0, m_u]])
        
        eigenvalues, eigenvectors = eigh(K, M)
        omega_squared = eigenvalues
        omega = np.sqrt(omega_squared)
        freq = omega / (2 * np.pi)
        participations = np.abs(eigenvectors[0,:])  # sprung mass DOF is index 0
        mode_index = np.argmax(participations)      # mode with largest sprung participation
        f_mode = freq[mode_index] # Sprung mass mode (lower frequency)
        
        return f_mode - f_target

    # Secant method implementation
    k_s_last, k_s_curr = k_s_lower, k_s_higher
    F_last, F_curr = rf_func(k_s_last), rf_func(k_s_curr)

    max_iterations = 50
    tolerance = 1e-4  # Hz

    print(f"Target frequency: {f_target} Hz Hz\n")

    for i in range(max_iterations):
        # Check convergence
        if abs(F_curr) < tolerance:
            print(f"found k in {i+1} iterations")
            break
        
        # Secant method update
        safe_gd = F_curr - F_last
        if abs(safe_gd) < 1e-12:
            safe_gd = np.sign(safe_gd) * 1e-12
        
        k_s_new = k_s_curr - F_curr * (k_s_curr - k_s_last) / safe_gd
        
        # Ensure positive stiffness
        if k_s_new <= 0:
            k_s_new = 1e-3
        
        # Update for next iteration
        k_s_last, F_last = k_s_curr, F_curr
        k_s_curr, F_curr = k_s_new, rf_func(k_s_new)
        
    else:
        print('✗ NO CONVERGENCE')
    per_spring=k_s_curr*0.5
    k_s_opt=k_s_curr
    print(f"k_s_opt={k_s_opt:.2f} N/m")
    return k_s_opt
def c_finder(k_opt, delta_target, M, k_t):
    def rf_func2(k_s, c_s):
        K = np.array([[k_s, -k_s],
                      [-k_s, k_s + k_t]])
        C = np.array([[c_s, -c_s],
                      [-c_s, c_s]])
        M_inv = np.linalg.inv(M)
        
        A = np.block([[np.zeros((2,2)), np.eye(2)],
                      [-M_inv @ K, -M_inv @ C]])
        eigvals, eigvecs = np.linalg.eig(A)


    # Only positive imaginary part (oscillatory)
        pos_idx = [i for i, lam in enumerate(eigvals) if np.imag(lam) > 1e-8]
        eigvals = eigvals[pos_idx]
        eigvecs = eigvecs[:, pos_idx]

    # Pick mode with largest sprung-mass participation
        participations = [abs(eigvecs[0,i]) for i in range(len(eigvals))]
        mode_index = np.argmax(participations)
        lam_mode = eigvals[mode_index]

        sigma = np.real(lam_mode)
        omega_d = np.imag(lam_mode)
        delta = -sigma / np.sqrt(sigma**2 + omega_d**2)
        return delta
    def objective_func(c_s):
        return rf_func2(k_s_opt, c_s)- delta_target
        

    c_lower, c_upper = 500, 1500


    c_last, c_curr = c_lower, c_upper
    F_last, F_curr = objective_func(c_last), objective_func(c_curr)

    max_step=500
    for i in range(50):
        if abs(F_curr) < 1e-4:  # Tolerance on damping ratio
            print(f"✓ found c in {i+1} iterations")
            break
        
        safe_gd = F_curr - F_last
        if abs(safe_gd) < 1e-12:
            safe_gd = np.sign(safe_gd) * 1e-12
        
        c_new = c_curr - F_curr * (c_curr - c_last) / safe_gd
        step = c_new - c_curr
        if abs(step) > max_step:
            step = np.sign(step) * max_step
        c_new = c_curr + step
        
       # Prevent unphysical or NaN values
        if np.isnan(c_new) or np.isinf(c_new):
            print("Warning: secant produced invalid c_s, stopping iteration")
            break
        
        
        c_last, F_last = c_curr, F_curr
        c_curr, F_curr = c_new, objective_func(c_new)

    c_s_opt = c_curr
    c_s_per_damper = c_s_opt / 2  # Twin shocks
    print(f"c_s_opt={c_s_opt:.2f} N/m")
    return c_s_opt

def road_analysis(k_s_opt, c_s_opt, roads, m_s, m_u, k_t):
    results=[]
    for road in roads:
        # === Cobbled Road Royal Mile ===
        df = pd.read_excel(road["file"])

        # velocity in m/s
        velocity = road["velocity_mph"] * 0.44704  

        # Extract data
        Latitude = df.iloc[:, 1].values
        Longitude = df.iloc[:, 2].values
        Altitude = df.iloc[:, 3].values

        # Convert degrees to meters
        conversion = 111139
        Latitude = np.array(Latitude) * conversion
        Longitude = np.array(Longitude) * conversion

        # Compute squared differences correctly
        Lat_diffs = np.diff(Latitude)
        Long_diffs = np.diff(Longitude)
        D2 = Lat_diffs**2 + Long_diffs**2
        D = np.sqrt(D2)

        # Cumulative distance (m)
        Dtotal = np.concatenate(([0.0], np.cumsum(D)))

        # Time = distance / velocity
        Ttotal = Dtotal / velocity

        # Make x-values for smooth interpolation
        x_lin = np.linspace(Ttotal[0], Ttotal[-1], 700)

        # Interpolation (set small smoothing for realistic curve)
        f_lin = interpolate.splrep(Ttotal, Altitude, s=5)
        Altitude_smooth = interpolate.splev(x_lin, f_lin, der=0)

        # Normalize road profile so it starts at 0 m
        Altitude_smooth -= Altitude_smooth[0]

        x_r_func = interpolate.interp1d(x_lin, Altitude_smooth, fill_value="extrapolate")
        x_r_dot_func = interpolate.splev(x_lin, f_lin, der=1)

        def x_r(t):
            return x_r_func(t)

        def x_r_dot(t):
            return float(np.interp(t, x_lin, x_r_dot_func))

        t_span = (0, x_lin.max())
        t_space = np.linspace(t_span[0], t_span[1], 1000)

        #c0 = 0.35*(2*(m_s*k_s)**0.5) #Ns/m
        alpha = 0.1 #10% variation due to environmental changes
        f = 1 #Hz frequency of variation of damping, allows for change every second
        
        def c(t):
            return c_s_opt * (1 + alpha * np.sin(2 * np.pi * f * t))

        def eom(t, y):
            x_s, x_s_dot, x_u, x_u_dot = y 
            xr = x_r(t)
            c_t = c(t)
            x_s_ddot = (1/m_s) * (-c_t * (x_s_dot - x_u_dot) - k_s_opt * (x_s - x_u))
            x_u_ddot = (1/m_u) * (c_t * (x_s_dot - x_u_dot) + k_s_opt * (x_s - x_u) - k_t * (x_u - xr))
            return [x_s_dot, x_s_ddot, x_u_dot, x_u_ddot]

        #Intial Condtitions to be changed [x_s, x_s_dot, x_u, x_u_dot]
        y0 = [0, 0, 0, 0]

        sol = solve_ivp(eom, t_span, y0, method='RK45', t_eval=t_space)

        # Extract results
        x_s, x_s_dot, x_u, x_u_dot = sol.y
        x_rp = x_r(sol.t)

        # Compute accelerations directly from eom()
        # (This ensures they are derived from the same ODE, not rederived manually)
        accels = np.array([eom(t, y) for t, y in zip(sol.t, sol.y.T)])
        x_s_ddot = accels[:, 1]
        x_u_ddot = accels[:, 3]
        
        t_start = 2.5  # seconds

        # Find the index where sol.t >= t_start
        idx_start = np.searchsorted(sol.t, t_start)

        # Slice time and corresponding data
        t_plot = sol.t[idx_start:]
        x_s_plot = x_s[idx_start:]
        x_s_ddot_plot = x_s_ddot[idx_start:]
        x_rp_plot = x_rp[idx_start:]
        
        "rms acceleration of sprung mass weighted with frequency of acclerations"
        "if frequencey of sprung mass acceleration lies in sensitive band more weight is given"
        "to that acceleration value , giving a better evaluation of comfort"
        
        # band-pass filter roughly covering human sensitivity (~0.5–8 Hz)
        lowcut = 0.5   # Hz
        highcut = 8   # Hz 
        fs = 1/np.mean(np.diff(t_plot))  # Sampling frequency from time array for filter

        b, a = butter(N=4, Wn=[lowcut/(fs/2), highcut/(fs/2)], btype='band')# butterworth filter
        #apply filter in both directions to accleration values
        x_s_ddot_weighted = filtfilt(b, a, x_s_ddot_plot) 
        #acceleration values now weighted
        
        #rms acceleration calculated
        a_rms_weighted = np.sqrt(np.mean(x_s_ddot_weighted**2))
        #print(f"{road['name']}: Weighted RMS acceleration = {a_rms_weighted:.5f} m/s²")
        results.append({
            "road": road["name"],
            "velocity_mph": road["velocity_mph"],
            "weighted_rms": a_rms_weighted
        })

    # Return list of results for all roads
    return results

    
f_targets = np.array([1.65, 1.75, 1.8, 1.85, 1.9, 1.95])        # Hz
delta_targets = np.linspace(0.2, 0.4, 5)     # damping ratios
results=[]
for f_t in f_targets:
    for d_t in delta_targets:
        print(f"\nRunning for f_target={f_t:.2f} Hz, ζ_target={d_t:.2f}")
        m_s = 63 #kg mass acting on the rear of the bike (61.5%)
        m_u = 15 #kg mass of rear wheel and tyre
        m_d = 80 #kg mass of the driver to work out inertial force 
        k_t = 100000 #N/m rear tyre stiffness
        M = np.array([[m_s + m_d, 0], 
                      [0, m_u]])


        k_s_opt = k_finder(f_t, m_s, m_u, m_d, k_t)
        c_s_opt = c_finder(k_s_opt, d_t, M, k_t)
        
        roads = [
            {"file": "Cobbled Road Royal Mile.xlsx", "name": "Cobbled Road Royal Mile", "velocity_mph": 20},
            {"file": "Liberton Road (A Road).xlsx", "name": "Liberton Road", "velocity_mph": 30},
            {"file": "Pleasance Road (hilly).xlsx", "name": "Pleasance Road", "velocity_mph": 20},
            {"file": "Redford Road (B Road).xlsx", "name": "Redford Road", "velocity_mph": 30},
        ]
        
        # running road simulations to evaluate weighted rms accleration
        road_metrics = road_analysis(k_s_opt, c_s_opt, roads, m_s, m_u, k_t)
        avg_rms = np.mean([r["weighted_rms"] for r in road_metrics])
        
        results.append({
            "f_target": f_t,
            "zeta_target": d_t,
            "k_s_opt": k_s_opt,
            "c_s_opt": c_s_opt,
            "mean_weighted_RMS": avg_rms
        })
        
df_results = pd.DataFrame(results)

heatmap_data = df_results.pivot(index="zeta_target", columns="f_target", values="mean_weighted_RMS")

plt.figure(figsize=(8,6))
# Use imshow
plt.imshow(heatmap_data, origin='lower', aspect='auto', cmap='viridis')
plt.colorbar(label='Mean Weighted RMS [m/s²]')
plt.xticks(ticks=np.arange(len(heatmap_data.columns)), labels=np.round(heatmap_data.columns, 2))
plt.yticks(ticks=np.arange(len(heatmap_data.index)), labels=np.round(heatmap_data.index, 2))
plt.xlabel("Target Frequency f [Hz]")
plt.ylabel("Target Damping ζ")
plt.title("Design Sweep Heatmap: Mean Weighted RMS Acceleration")
plt.show()

# Find design with lowest mean weighted RMS
best_idx = df_results["mean_weighted_RMS"].idxmin()
best_design = df_results.loc[best_idx]

print("BEST SUSPENSION DESIGN FOUND")
print(f"Target Frequency (f_target): {best_design['f_target']:.2f} Hz")
print(f"Target Damping Ratio (ζ_target): {best_design['zeta_target']:.2f}")
print(f"Optimal Spring Stiffness (k_s_opt): {best_design['k_s_opt']:.2f} N/m")
print(f"Optimal Damping Coefficient (c_s_opt): {best_design['c_s_opt']:.2f} N·s/m")
print(f"Mean Weighted RMS Acceleration: {best_design['mean_weighted_RMS']:.5f} m/s²")
print("="*70)


print("\nAll designs sorted by comfort (ascending RMS):")
print(df_results.sort_values("mean_weighted_RMS").reset_index(drop=True))     
